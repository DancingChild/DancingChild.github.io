---
layout:     post
title:      Pytorch 数据读取
subtitle:   Dataset，Dataloader类的学习
date:       2019-07-27
author:     liyang
header-img: img/Rio2.png
catalog: true
tags:
    - Pytorch
    - python
    - 数据读取
---

# Pytorch 数据读取

最近打算从TF转到pytorch，学了一下pytorch的数据输入。

Pytorch的数据读取非常方便, 可以很容易地实现多线程数据预读. 主要包含三个类:

Dataset

DataLoader

DataLoaderIter

这三者大致是一个依次封装的关系: 1.被装进2., 2.被装进3.

##  一. torch.utils.data.Dataset

是一个抽象类, 主要有三个成员函数:

~~~python
__init__()
__getitem__()
__len__()
~~~



自定义的Dataset需要继承它并且实现两个成员方法:

~~~python
__getitem__()
__len__()
~~~

第一个初始化函数里面一般要初始化一个images_path的列表，一个target的列表

```python
def __init__(self, ):
    #定义好 image 的路径
    self.images = file_train
    self.target = number_train
```

第二个最为重要, 即每次怎么读数据. 以图片为例:

 ~~~python
def __getitem__(self, index):     
    img_path, label = self.data[index].img_path, self.data[index].label 
    img = Image.open(img_path)
    return img, label
 ~~~

对于复杂的输入，可能还要构建更多的函数，或者传入loader函数，以实现每次训练所有数据的一个item。同时还可以在此处做数据增强，定义好数据增强函数，在此函数内调用即可。 pytorch还提供了很多常用的transform, 在torchvision.transforms 里面, 常用的有Resize , RandomCrop , Normalize , ToTensor (这个极为重要, 可以把一个PIL或numpy图片转为torch.Tensor, 但是好像对numpy数组的转换比较受限, 所以这里建议在__getitem__()里面用PIL来读图片, 而不是用skimage.io). 

第三个比较简单, 就是返回整个数据集的长度:

~~~ python
def __len__(self):
    return len(self.data)
~~~





##  二. torch.utils.data.DataLoader

类定义为:

~~~python
class torch.utils.data.DataLoader(dataset, 
                                  batch_size=1, 
                                  shuffle=False,
                                  sampler=None,
                                  batch_sampler=None, 
                                  num_workers=0,
                                  collate_fn=<function default_collate>, 
                                  pin_memory=False, drop_last=False)
~~~

可以看到, 主要参数有这么几个:

dataset : 即上面自定义的dataset.

collate_fn: 这个函数用来打包batch, 后面详细讲.

num_worker: 非常简单的多线程方法, 只要设置为>=1, 就可以多线程预读数据啦.

这个类其实就是下面将要讲的DataLoaderIter的一个框架, 一共干了两件事: 1.定义了一堆成员变量, 到时候赋给DataLoaderIter, 2.然后有一个__iter__() 函数, 把自己 "装进" DataLoaderIter 里面.

~~~python
def __iter__(self):
         return DataLoaderIter(self)
~~~



## 三. torch.utils.data.dataloader.DataLoaderIter

上面提到, DataLoaderIter就是DataLoaderIter的一个框架, 用来传给DataLoaderIter 一堆参数, 并把自己装进DataLoaderIter 里.

其实到这里就可以满足大多数训练的需求了, 比如

class CustomDataset(Dataset):
    \# 自定义自己的dataset

dataset = CustomDataset()
 dataloader = Dataloader(dataset, ...)

for data in dataloader:
    \# training...

在for 循环里, 总共有三点操作:

调用了dataloader 的__iter__() 方法, 产生了一个DataLoaderIter

反复调用DataLoaderIter 的__next__()来得到batch, 具体操作就是, 多次调用dataset的__getitem__()方法 (如果num_worker>0就多线程调用), 然后用collate_fn来把它们打包成batch. 中间还会涉及到shuffle , 以及sample 的方法等, 这里就不多说了.

当数据读完后, __next__()抛出一个StopIteration异常, for循环结束, dataloader 失效.
